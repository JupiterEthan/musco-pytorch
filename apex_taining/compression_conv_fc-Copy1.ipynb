{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catalyst.dl.callbacks import Callback, AccuracyCallback\n",
    "from catalyst.dl.experiments import SupervisedRunner\n",
    "\n",
    "from collections import OrderedDict, defaultdict\n",
    "\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = OrderedDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building imagenet data loader with 32 workers\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import dataloaders\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "# DATA_ROOT = \"/workspace/raid/data/datasets\"\n",
    "DATA_ROOT = \"/gpfs/gpfs0/e.ponomarev/\"\n",
    "dataset_name = 'imagenet'\n",
    "\n",
    "bs = 128\n",
    "num_workers = 32\n",
    "\n",
    "if dataset_name == 'cifar10':\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    DATA_PATH = \"{}/cifar10\".format(DATA_ROOT)\n",
    "\n",
    "    loaders[\"valid\"] = torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR10(root=DATA_PATH, train=False, transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]),  download = True),\n",
    "        batch_size=bs, shuffle=False,\n",
    "        num_workers=num_workers, pin_memory=True)\n",
    "elif dataset_name == 'imagenet':\n",
    "    loaders[\"valid\"] = dataloaders.get_loader(batch_size=bs,\n",
    "                                        data_name = 'imagenet',\n",
    "                                        data_root = DATA_ROOT,\n",
    "                                        num_workers = num_workers, \n",
    "                                        pin_memory = True)['val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyInferCallback(Callback):\n",
    "    \n",
    "    \n",
    "    def __init__(self, out_dir=None, out_prefix=None):\n",
    "        self.out_dir = out_dir\n",
    "        self.out_prefix = out_prefix\n",
    "        self.predictions = defaultdict(lambda: [])\n",
    "        self._keys_from_state = [\"out_dir\", \"out_prefix\"]\n",
    "\n",
    "    def on_stage_start(self, state):\n",
    "        for key in self._keys_from_state:\n",
    "            value = getattr(state, key, None)\n",
    "            if value is not None:\n",
    "                setattr(self, key, value)\n",
    "        # assert self.out_prefix is not None\n",
    "        if self.out_dir is not None:\n",
    "            self.out_prefix = str(self.out_dir) + \"/\" + str(self.out_prefix)\n",
    "        if self.out_prefix is not None:\n",
    "            os.makedirs(os.path.dirname(self.out_prefix), exist_ok=True)\n",
    "\n",
    "    def on_loader_start(self, state):\n",
    "        self.predictions = defaultdict(lambda: [])\n",
    "        self.inputs = defaultdict(lambda: [])\n",
    "\n",
    "    def on_batch_end(self, state):\n",
    "        dct = state.output\n",
    "        dct = {key: value.detach().cpu().numpy() for key, value in dct.items()}\n",
    "        for key, value in dct.items():\n",
    "            self.predictions[key].append(value)\n",
    "            \n",
    "        dct = state.input\n",
    "        dct = {key: value.detach().cpu().numpy() for key, value in dct.items()}\n",
    "        for key, value in dct.items():\n",
    "            self.inputs[key].append(value)\n",
    "\n",
    "    def on_loader_end(self, state):\n",
    "        from catalyst.dl.metrics import accuracy\n",
    "        self.predictions = {\n",
    "            key: np.concatenate(value, axis=0)\n",
    "            for key, value in self.predictions.items()\n",
    "        }\n",
    "        self.inputs = {\n",
    "            key: np.concatenate(value, axis=0)\n",
    "            for key, value in self.inputs.items()\n",
    "        }\n",
    "        y_true = torch.tensor(self.inputs['targets'])\n",
    "        y_pred = torch.tensor(self.predictions['logits'])\n",
    "        self.accuracy_score = torch.stack(accuracy(y_pred,y_true,topk=(1, 3, 5))).numpy().astype('float32')\n",
    "        self.accuracy_score = np.squeeze(self.accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(model, device = 'cuda'):\n",
    "\n",
    "    runner = SupervisedRunner()\n",
    "    runner.infer(\n",
    "        model=model.to(device),\n",
    "        verbose = True,\n",
    "        loaders=OrderedDict([(\"infer\", loaders[\"valid\"])]),\n",
    "        callbacks=[\n",
    "            MyInferCallback(),\n",
    "            AccuracyCallback(accuracy_args=[1, 3, 5])\n",
    "        ],\n",
    "    )\n",
    "    score = runner.callbacks[0].accuracy_score\n",
    "    del model\n",
    "    del runner\n",
    "    torch.cuda.empty_cache()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from model_utils import load_model\n",
    "from torchvision.models import resnet34, resnet18\n",
    "\n",
    "# MODEL_NAME = 'vgg16_imagenet'\n",
    "# MODEL_NAME = 'resnet50_imagenet'\n",
    "MODEL_NAME = 'resnet18_imagenet'\n",
    "# MODEL_NAME = 'resnet34_imagenet'\n",
    "\n",
    "# MODEL_NAME = 'faster_rcnn_vgg16\n",
    "# MODEL_NAME = 'faster_rcnn_resnet50'\n",
    "\n",
    "\n",
    "# # Uncomment if MODEL_NAME = 'faster_rcnn_resnet50'\n",
    "# sys.path.append('/workspace/home/jgusak/maxvol_objects/facebook_frcnn/')\n",
    "# import maskrcnn_benchmark\n",
    "\n",
    "# model = load_model(MODEL_NAME)\n",
    "\n",
    "model = resnet18(pretrained = True)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in model.parameters():\n",
    "#     print(p.requires_grad)\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from catalyst.dl.callbacks import InferCallback\n",
    "from collections import OrderedDict\n",
    "\n",
    "runner = SupervisedRunner()\n",
    "\n",
    "runner.infer(\n",
    "    model=model,\n",
    "    loaders = OrderedDict([(\"infer\", loaders[\"valid\"])]),\n",
    "    callbacks=[InferCallback(),\n",
    "               AccuracyCallback(accuracy_args=[1, 3, 5])],\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/1 * Epoch (infer): 100% 391/391 [00:50<00:00, 10.77it/s, _timers/_fps=863.038, accuracy01=42.500, accuracy03=73.750, accuracy05=77.500]  \n"
     ]
    }
   ],
   "source": [
    "scores0 = run(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([69.758   , 84.95801 , 89.076004], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "del runner\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "scores0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get  all  layers\n",
    "\n",
    "Function  **get_layer_names()** returns names of model layers (convolutional and fully connected) and boolean mask for convolutional layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['conv1' 'layer1.0.conv1' 'layer1.0.conv2' 'layer1.1.conv1'\n",
      " 'layer1.1.conv2' 'layer2.0.conv1' 'layer2.0.conv2'\n",
      " 'layer2.0.downsample.0' 'layer2.1.conv1' 'layer2.1.conv2'\n",
      " 'layer3.0.conv1' 'layer3.0.conv2' 'layer3.0.downsample.0'\n",
      " 'layer3.1.conv1' 'layer3.1.conv2' 'layer4.0.conv1' 'layer4.0.conv2'\n",
      " 'layer4.0.downsample.0' 'layer4.1.conv1' 'layer4.1.conv2']\n",
      "['fc']\n"
     ]
    }
   ],
   "source": [
    "from model_utils import get_layer_names\n",
    "\n",
    "layer_names, conv_layer_mask = get_layer_names(model)\n",
    "\n",
    "\n",
    "fc_layer_mask = (1 - conv_layer_mask).astype(bool)\n",
    "\n",
    "print(layer_names[conv_layer_mask])\n",
    "print(layer_names[fc_layer_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auxiliary function\n",
    "import numpy as np\n",
    "def split_resnet_layers_by_blocks(lnames):\n",
    "#     starts = ['body.stem.conv1'] + ['body.layer{}'.format(i) for i in range(1,5)]\n",
    "    starts = ['conv1'] + ['layer{}'.format(i) for i in range(1,5)]\n",
    "\n",
    "\n",
    "    start_idx = 0\n",
    "    blocks_idxs = []\n",
    "    layer_names_by_blocks = []\n",
    "\n",
    "    for s in starts:\n",
    "        curr_block =  [l for l in lnames if l.startswith(s)]\n",
    "        layer_names_by_blocks.append(curr_block)\n",
    "\n",
    "        blocks_idxs.append(np.arange(start_idx, start_idx+len(curr_block)))\n",
    "        start_idx += len(curr_block)\n",
    "\n",
    "    return blocks_idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compress selected layers\n",
    "\n",
    "For **convolutional** layers\n",
    "- Set **decomposition**: 'tucker2', 'cp3' or 'cp4'\n",
    "- Set  decomposition **ranks** for convolutional layers (namely, ranks we use to decompose convolutional weight tensors). \n",
    "  - In Tucker2 case, for one layer \n",
    "      - If **rank = None**, the layer won't be decomposed.\n",
    "      - Elif **rank = 0**, then  VBMF method with **vbmf_weaken_factor**  will be used to select (rank_cout, rank_cin).\n",
    "      - Elif **rank = (-scalar) < 0**, then values (rank_cout, rank_cin) will be choosen as maximal values which allow **(sacalar x) layer parameter reduction**.\n",
    "      - Else **rank = tuple** and determines absolute ranks values (rank_cout, rank_cin)\n",
    "  - In CP case, rank for one layer is a scalar\n",
    "      - If **rank = None**, the layer won't be decomposed.\n",
    "      - Elif **rank = (-scalar) < 0** then value for rank will be choosen as maximal rank which allows **(sacalar x) layer parameter reduction**.\n",
    "      - Else **rank = scalar > 0** and determines absolute rank value.\n",
    "      \n",
    "For **fully connected** layers\n",
    "- Set **decomposition** = 'svd'\n",
    "- Set decomposition for linear layers (namely, ranks we use to factorize weight matrices)\n",
    "    - In SVD case, rank for one layer is a scalar\n",
    "      - If **rank = None**, the layer won't be decomposed.\n",
    "      - Elif **rank = 0**, then  VBMF method with **vbmf_weaken_factor**  will be used to select rank.\n",
    "      - Elif **rank = (-scalar) < 0** then value for rank will be choosen as maximal rank which allows **(sacalar x) layer parameter reduction**.\n",
    "      - Else **rank = scalar > 0** and determines absolute rank value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensor_compression import get_compressed_model\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "# decomposition_conv = 'cp4'\n",
    "# decomposition_conv = 'cp3'\n",
    "decomposition_conv = 'tucker2'\n",
    "\n",
    "decomposition_fc = 'svd'\n",
    "\n",
    "RANK_SELECTION = 'vbmf'\n",
    "# RANK_SELECTION = 'nx'\n",
    "# RANK_SELECTION = 'custom'\n",
    "\n",
    "if RANK_SELECTION == 'vbmf':\n",
    "    WEAKEN_FACTOR = 1.\n",
    "    X_FACTOR = 0\n",
    "    rank_selection_suffix = \"/wf:{}\".format(WEAKEN_FACTOR)\n",
    "elif RANK_SELECTION == 'nx':\n",
    "    WEAKEN_FACTOR = None  \n",
    "    X_FACTOR = 10\n",
    "    rank_selection_suffix = \"/{}x\".format(X_FACTOR)\n",
    "    \n",
    "    \n",
    "if MODEL_NAME == 'vgg16_imagenet':\n",
    "    ranks_conv = [None] + [-X_FACTOR]*(len(layer_names[conv_layer_mask])-1)\n",
    "\n",
    "elif MODEL_NAME == 'resnet50_imagenet':\n",
    "    ranks_conv = [None if not name.endswith('conv2') else -X_FACTOR\n",
    "                  for name in layer_names[conv_layer_mask]]\n",
    "\n",
    "elif MODEL_NAME in ['resnet18_imagenet', 'resnet34_imagenet']:\n",
    "    ranks_conv = [None if name == 'conv1' or not (name.endswith('conv2') or\n",
    "                                                  name.endswith('conv1')) else -X_FACTOR\n",
    "              for name in layer_names[conv_layer_mask]]\n",
    "\n",
    "elif MODEL_NAME ==  'faster_rcnn_resnet50':\n",
    "    ranks_conv = [None if not name.endswith('body.conv2') else -X_FACTOR\n",
    "                  for name in layer_names[conv_layer_mask]]\n",
    "\n",
    "# ranks_fc = [-X_FACTOR]*(len(layer_names[fc_layer_mask]))\n",
    "ranks_fc = [None]*(len(layer_names[fc_layer_mask]))\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "ranks = np.array([None]*len(layer_names))\n",
    "ranks[conv_layer_mask] = ranks_conv\n",
    "ranks[fc_layer_mask] = ranks_fc\n",
    "\n",
    "decompositions = np.array([None]*len(layer_names))\n",
    "decompositions[conv_layer_mask] = decomposition_conv\n",
    "decompositions[fc_layer_mask] = decomposition_fc\n",
    "\n",
    "CONV_SPLIT = 20\n",
    "FC_SPLIT = 1\n",
    "n_layers = len(layer_names)\n",
    "\n",
    "RESNET_SPLIT = False\n",
    "if MODEL_NAME in ['resnet50_imagenet', 'resnet34_imagenet', 'resnet18_imagenet',  'faster_rcnn_resnet50'] and RESNET_SPLIT:\n",
    "    split_tuples = split_resnet_layers_by_blocks(layer_names[conv_layer_mask])[::-1]\n",
    "else:\n",
    "    split_tuples = np.array_split(np.arange(n_layers)[conv_layer_mask], CONV_SPLIT)[::-1]\n",
    "split_tuples.append(np.array_split(np.arange(n_layers)[fc_layer_mask], FC_SPLIT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['layer4.1.conv2']\n",
      "['layer4.1.conv1']\n",
      "['layer4.0.downsample.0']\n",
      "['layer4.0.conv2']\n",
      "['layer4.0.conv1']\n",
      "['layer3.1.conv2']\n",
      "['layer3.1.conv1']\n",
      "['layer3.0.downsample.0']\n",
      "['layer3.0.conv2']\n",
      "['layer3.0.conv1']\n",
      "['layer2.1.conv2']\n",
      "['layer2.1.conv1']\n",
      "['layer2.0.downsample.0']\n",
      "['layer2.0.conv2']\n",
      "['layer2.0.conv1']\n",
      "['layer1.1.conv2']\n",
      "['layer1.1.conv1']\n",
      "['layer1.0.conv2']\n",
      "['layer1.0.conv1']\n",
      "['conv1']\n",
      "['fc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/trinity/shared/opt/python-3.7.1/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning:\n",
      "\n",
      "Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tupl in split_tuples:\n",
    "    print(layer_names[tupl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['layer4.1.conv2'] [0]\n",
      "Decompose layer layer4.1.conv2\n",
      "-------------------- SVD time:  10.672295570373535\n",
      "------------------- VBMF time :  10.674672603607178\n",
      "-------------------- SVD time:  3.7167229652404785\n",
      "------------------- VBMF time :  3.719432830810547\n",
      "\t new rank:  [307, 279]\n",
      "================ time : 80.40685558319092\n",
      "0/1 * Epoch (infer): 100% 391/391 [01:00<00:00, 11.34it/s, _timers/_fps=2610.072, accuracy01=37.500, accuracy03=71.250, accuracy05=76.250] \n",
      "[69.324005 84.86201  88.996   ]\n",
      "['layer4.1.conv1'] [0]\n",
      "Decompose layer layer4.1.conv1\n",
      "-------------------- SVD time:  2.7068915367126465\n",
      "------------------- VBMF time :  2.708742380142212\n",
      "-------------------- SVD time:  2.610800266265869\n",
      "------------------- VBMF time :  2.612825632095337\n",
      "\t new rank:  [114, 127]\n",
      "================ time : 911.5126481056213\n",
      "0/1 * Epoch (infer): 100% 391/391 [01:02<00:00,  6.22it/s, _timers/_fps=3996.449, accuracy01=52.500, accuracy03=78.750, accuracy05=85.000] \n",
      "[54.640003 73.816    80.204   ]\n",
      "['layer4.0.downsample.0'] [None]\n",
      "Skip layer layer4.0.downsample.0\n",
      "================ time : 0.5982668399810791\n",
      "0/1 * Epoch (infer): 100% 391/391 [01:00<00:00,  6.51it/s, _timers/_fps=18343.900, accuracy01=52.500, accuracy03=78.750, accuracy05=85.000]\n",
      "[54.640003 73.816    80.204   ]\n",
      "['layer4.0.conv2'] [0]\n",
      "Decompose layer layer4.0.conv2\n",
      "-------------------- SVD time:  3.2927722930908203\n",
      "------------------- VBMF time :  3.296996831893921\n",
      "-------------------- SVD time:  3.3219833374023438\n",
      "------------------- VBMF time :  3.325587272644043\n",
      "\t new rank:  [97, 107]\n",
      "================ time : 777.3982853889465\n",
      "0/1 * Epoch (infer): 100% 391/391 [00:59<00:00,  6.52it/s, _timers/_fps=4353.760, accuracy01=43.750, accuracy03=72.500, accuracy05=81.250] \n",
      "[42.338 62.852 70.97 ]\n",
      "['layer4.0.conv1'] [0]\n",
      "Decompose layer layer4.0.conv1\n",
      "-------------------- SVD time:  0.4978799819946289\n",
      "------------------- VBMF time :  0.4992227554321289\n",
      "-------------------- SVD time:  2.586073398590088\n",
      "------------------- VBMF time :  2.588069438934326\n",
      "\t new rank:  [126, 93]\n",
      "================ time : 333.4538848400116\n",
      "0/1 * Epoch (infer): 100% 391/391 [00:53<00:00, 13.03it/s, _timers/_fps=4336.634, accuracy01=36.250, accuracy03=63.750, accuracy05=71.250] \n",
      "[37.878002 57.868004 66.41    ]\n",
      "['layer3.1.conv2'] [0]\n",
      "Decompose layer layer3.1.conv2\n",
      "-------------------- SVD time:  0.3936424255371094\n",
      "------------------- VBMF time :  0.39563441276550293\n",
      "-------------------- SVD time:  0.5261404514312744\n",
      "------------------- VBMF time :  0.5312612056732178\n",
      "\t new rank:  [68, 53]\n",
      "================ time : 62.760772943496704\n",
      "0/1 * Epoch (infer): 100% 391/391 [00:52<00:00, 15.25it/s, _timers/_fps=4618.244, accuracy01=37.500, accuracy03=61.250, accuracy05=68.750] \n",
      "[32.736    52.184002 61.120003]\n",
      "['layer3.1.conv1'] [0]\n",
      "Decompose layer layer3.1.conv1\n",
      "-------------------- SVD time:  0.40833568572998047\n",
      "------------------- VBMF time :  0.41108012199401855\n",
      "-------------------- SVD time:  0.4528791904449463\n",
      "------------------- VBMF time :  0.45444416999816895\n",
      "\t new rank:  [61, 75]\n",
      "================ time : 21.51590061187744\n",
      "0/1 * Epoch (infer): 100% 391/391 [00:50<00:00, 13.51it/s, _timers/_fps=4575.656, accuracy01=48.750, accuracy03=62.500, accuracy05=66.250] \n",
      "[29.706001 48.15     56.894   ]\n",
      "['layer3.0.downsample.0'] [None]\n",
      "Skip layer layer3.0.downsample.0\n",
      "================ time : 0.635350227355957\n",
      "0/1 * Epoch (infer): 100% 391/391 [00:55<00:00,  7.01it/s, _timers/_fps=15800.080, accuracy01=48.750, accuracy03=62.500, accuracy05=66.250]\n",
      "[29.706001 48.15     56.894   ]\n",
      "['layer3.0.conv2'] [0]\n",
      "Decompose layer layer3.0.conv2\n",
      "-------------------- SVD time:  0.46170783042907715\n",
      "------------------- VBMF time :  0.46475768089294434\n",
      "-------------------- SVD time:  0.6112165451049805\n",
      "------------------- VBMF time :  0.6129755973815918\n",
      "\t new rank:  [73, 84]\n",
      "================ time : 19.111597299575806\n",
      "0/1 * Epoch (infer): 100% 391/391 [00:45<00:00, 15.55it/s, _timers/_fps=4689.812, accuracy01=46.250, accuracy03=66.250, accuracy05=68.750] \n",
      "[24.552002 41.480003 49.808002]\n",
      "['layer3.0.conv1'] [0]\n",
      "Decompose layer layer3.0.conv1\n",
      "-------------------- SVD time:  0.43122243881225586\n",
      "------------------- VBMF time :  0.43967103958129883\n",
      "-------------------- SVD time:  0.5561621189117432\n",
      "------------------- VBMF time :  0.5580055713653564\n",
      "\t new rank:  [77, 54]\n",
      "================ time : 17.65218210220337\n",
      "0/1 * Epoch (infer): 100% 391/391 [00:55<00:00,  7.05it/s, _timers/_fps=4686.128, accuracy01=27.500, accuracy03=56.250, accuracy05=63.750] \n",
      "[19.252 33.922 41.922]\n",
      "['layer2.1.conv2'] [0]\n",
      "Decompose layer layer2.1.conv2\n",
      "-------------------- SVD time:  0.15469646453857422\n",
      "------------------- VBMF time :  0.1563246250152588\n",
      "-------------------- SVD time:  0.21325182914733887\n",
      "------------------- VBMF time :  0.21491503715515137\n",
      "\t new rank:  [29, 22]\n",
      "================ time : 22.850077867507935\n",
      "0/1 * Epoch (infer): 100% 391/391 [00:55<00:00,  7.01it/s, _timers/_fps=5307.146, accuracy01=21.250, accuracy03=45.000, accuracy05=53.750] \n",
      "[ 9.548    18.986    25.078001]\n",
      "['layer2.1.conv1'] [0]\n",
      "Decompose layer layer2.1.conv1\n",
      "-------------------- SVD time:  0.15792036056518555\n",
      "------------------- VBMF time :  0.16004610061645508\n",
      "-------------------- SVD time:  0.2266848087310791\n",
      "------------------- VBMF time :  0.2292165756225586\n",
      "\t new rank:  [31, 38]\n",
      "================ time : 10.461917638778687\n",
      "0/1 * Epoch (infer): 100% 391/391 [00:54<00:00,  7.11it/s, _timers/_fps=5252.677, accuracy01=18.750, accuracy03=38.750, accuracy05=47.500] \n",
      "[ 6.6320004 14.438001  19.524    ]\n",
      "['layer2.0.downsample.0'] [None]\n",
      "Skip layer layer2.0.downsample.0\n",
      "================ time : 0.6252658367156982\n",
      "0/1 * Epoch (infer): 100% 391/391 [00:42<00:00, 16.25it/s, _timers/_fps=16633.235, accuracy01=18.750, accuracy03=38.750, accuracy05=47.500]\n",
      "[ 6.6320004 14.438001  19.524    ]\n",
      "['layer2.0.conv2'] [0]\n",
      "Decompose layer layer2.0.conv2\n",
      "-------------------- SVD time:  0.19759583473205566\n",
      "------------------- VBMF time :  0.20090460777282715\n",
      "-------------------- SVD time:  0.14722180366516113\n",
      "------------------- VBMF time :  0.14871001243591309\n",
      "\t new rank:  [40, 47]\n",
      "================ time : 8.612420082092285\n",
      "0/1 * Epoch (infer): 100% 391/391 [01:00<00:00, 16.54it/s, _timers/_fps=5024.294, accuracy01=16.250, accuracy03=41.250, accuracy05=52.500] \n",
      "[ 4.346     9.344001 12.732   ]\n",
      "['layer2.0.conv1'] [0]\n",
      "Decompose layer layer2.0.conv1\n",
      "-------------------- SVD time:  0.1705913543701172\n",
      "------------------- VBMF time :  0.17336630821228027\n",
      "-------------------- SVD time:  0.08450889587402344\n",
      "------------------- VBMF time :  0.08803582191467285\n",
      "\t new rank:  [25, 32]\n",
      "================ time : 15.599301099777222\n",
      "0/1 * Epoch (infer): 100% 391/391 [01:00<00:00, 15.13it/s, _timers/_fps=5311.977, accuracy01=16.250, accuracy03=30.000, accuracy05=41.250] \n",
      "[1.46      3.4840002 5.0540004]\n",
      "['layer1.1.conv2'] [0]\n",
      "Decompose layer layer1.1.conv2\n",
      "-------------------- SVD time:  0.07862520217895508\n",
      "------------------- VBMF time :  0.07956123352050781\n",
      "-------------------- SVD time:  0.039220333099365234\n",
      "------------------- VBMF time :  0.04026675224304199\n",
      "\t new rank:  [20, 18]\n",
      "================ time : 3.7786617279052734\n",
      "0/1 * Epoch (infer): 100% 391/391 [01:00<00:00, 13.61it/s, _timers/_fps=5125.700, accuracy01=13.750, accuracy03=27.500, accuracy05=31.250] \n",
      "[0.71800005 1.95       2.8880002 ]\n",
      "['layer1.1.conv1'] [0]\n",
      "Decompose layer layer1.1.conv1\n",
      "-------------------- SVD time:  0.04216742515563965\n",
      "------------------- VBMF time :  0.04418349266052246\n",
      "-------------------- SVD time:  0.03152012825012207\n",
      "------------------- VBMF time :  0.032567739486694336\n",
      "\t new rank:  [21, 21]\n",
      "================ time : 3.053502082824707\n",
      "0/1 * Epoch (infer): 100% 391/391 [01:00<00:00, 12.52it/s, _timers/_fps=4768.922, accuracy01=7.500, accuracy03=15.000, accuracy05=17.500]  \n",
      "[0.84200007 2.196      3.272     ]\n",
      "['layer1.0.conv2'] [0]\n",
      "Decompose layer layer1.0.conv2\n",
      "-------------------- SVD time:  0.0675811767578125\n",
      "------------------- VBMF time :  0.06885480880737305\n",
      "-------------------- SVD time:  0.03066873550415039\n",
      "------------------- VBMF time :  0.03164315223693848\n",
      "\t new rank:  [24, 23]\n",
      "================ time : 7.720405340194702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/1 * Epoch (infer): 100% 391/391 [01:00<00:00,  9.98it/s, _timers/_fps=5071.758, accuracy01=12.500, accuracy03=20.000, accuracy05=22.500] \n",
      "[0.76000005 1.9020001  2.9180002 ]\n",
      "['layer1.0.conv1'] [0]\n",
      "Decompose layer layer1.0.conv1\n",
      "-------------------- SVD time:  0.0765542984008789\n",
      "------------------- VBMF time :  0.07866263389587402\n",
      "-------------------- SVD time:  0.03251314163208008\n",
      "------------------- VBMF time :  0.03909182548522949\n",
      "\t new rank:  [29, 40]\n",
      "================ time : 1.6788005828857422\n",
      "0/1 * Epoch (infer): 100% 391/391 [01:00<00:00, 12.42it/s, _timers/_fps=4706.504, accuracy01=10.000, accuracy03=17.500, accuracy05=23.750] \n",
      "[0.804 2.138 3.19 ]\n",
      "['conv1'] [None]\n",
      "Skip layer conv1\n",
      "================ time : 0.756927490234375\n",
      "0/1 * Epoch (infer): 100% 391/391 [01:03<00:00,  6.18it/s, _timers/_fps=15746.786, accuracy01=10.000, accuracy03=17.500, accuracy05=23.750]\n",
      "[0.804 2.138 3.19 ]\n",
      "['fc'] [None]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/trinity/shared/opt/python-3.7.1/lib/python3.7/site-packages/ipykernel_launcher.py:7: FutureWarning:\n",
      "\n",
      "Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skip layer fc\n",
      "================ time : 0.4597179889678955\n",
      "0/1 * Epoch (infer): 100% 391/391 [01:00<00:00,  6.48it/s, _timers/_fps=15148.300, accuracy01=10.000, accuracy03=17.500, accuracy05=23.750]\n",
      "[0.804 2.138 3.19 ]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "scores = defaultdict(list)\n",
    "\n",
    "compressed_model = copy.deepcopy(model.cpu())\n",
    "for tupl in split_tuples:\n",
    "    lname, rank, decomposition = layer_names[tupl], ranks[tupl], decompositions[tupl]\n",
    "    print(lname, rank)\n",
    "    start = time.time()\n",
    "    compressed_model = get_compressed_model(compressed_model,\n",
    "                                            ranks=rank,\n",
    "                                            layer_names=lname,\n",
    "                                            decompositions = decomposition,\n",
    "                                            vbmf_weaken_factor=WEAKEN_FACTOR)\n",
    "    end = time.time()\n",
    "    print('================ time : {}'.format(end - start))\n",
    "    score = run(copy.deepcopy(compressed_model))\n",
    "    print(score)\n",
    "#     scores[tupl[0]] = score\n",
    "    scores[layer_names[tupl[0]][0]] = score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'l': array([0.804, 2.138, 3.19 ], dtype=float32),\n",
       "             'c': array([0.804, 2.138, 3.19 ], dtype=float32),\n",
       "             'fc': array([0.804, 2.138, 3.19 ], dtype=float32)})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def count_params(model):\n",
    "    n_params = 0\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        n_params += param.numel()\n",
    "    return n_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.232299048353415"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_count_dict_m = count_params(model)\n",
    "params_count_dict_cm = count_params(compressed_model)\n",
    "\n",
    "params_count_dict_m / params_count_dict_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute FLOPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compressed_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from flopco import FlopCo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (conv1-0): Conv2d(64, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv1-1): Conv2d(36, 36, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=36, bias=False)\n",
       "        (conv1-2): Conv2d(36, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Sequential(\n",
       "        (conv2-0): Conv2d(128, 55, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2-1): Conv2d(55, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=55, bias=False)\n",
       "        (conv2-2): Conv2d(55, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (conv1-0): Conv2d(128, 55, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv1-1): Conv2d(55, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=55, bias=False)\n",
       "        (conv1-2): Conv2d(55, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Sequential(\n",
       "        (conv2-0): Conv2d(128, 55, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2-1): Conv2d(55, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=55, bias=False)\n",
       "        (conv2-2): Conv2d(55, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (conv1-0): Conv2d(128, 55, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv1-1): Conv2d(55, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=55, bias=False)\n",
       "        (conv1-2): Conv2d(55, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Sequential(\n",
       "        (conv2-0): Conv2d(128, 55, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2-1): Conv2d(55, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=55, bias=False)\n",
       "        (conv2-2): Conv2d(55, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (conv1-0): Conv2d(128, 55, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv1-1): Conv2d(55, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=55, bias=False)\n",
       "        (conv1-2): Conv2d(55, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Sequential(\n",
       "        (conv2-0): Conv2d(128, 55, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2-1): Conv2d(55, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=55, bias=False)\n",
       "        (conv2-2): Conv2d(55, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (conv1-0): Conv2d(128, 75, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv1-1): Conv2d(75, 75, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=75, bias=False)\n",
       "        (conv1-2): Conv2d(75, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Sequential(\n",
       "        (conv2-0): Conv2d(256, 113, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2-1): Conv2d(113, 113, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=113, bias=False)\n",
       "        (conv2-2): Conv2d(113, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (conv1-0): Conv2d(256, 113, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv1-1): Conv2d(113, 113, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=113, bias=False)\n",
       "        (conv1-2): Conv2d(113, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Sequential(\n",
       "        (conv2-0): Conv2d(256, 113, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2-1): Conv2d(113, 113, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=113, bias=False)\n",
       "        (conv2-2): Conv2d(113, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (conv1-0): Conv2d(256, 113, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv1-1): Conv2d(113, 113, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=113, bias=False)\n",
       "        (conv1-2): Conv2d(113, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Sequential(\n",
       "        (conv2-0): Conv2d(256, 113, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2-1): Conv2d(113, 113, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=113, bias=False)\n",
       "        (conv2-2): Conv2d(113, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (conv1-0): Conv2d(256, 113, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv1-1): Conv2d(113, 113, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=113, bias=False)\n",
       "        (conv1-2): Conv2d(113, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Sequential(\n",
       "        (conv2-0): Conv2d(256, 113, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2-1): Conv2d(113, 113, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=113, bias=False)\n",
       "        (conv2-2): Conv2d(113, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (conv1-0): Conv2d(256, 113, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv1-1): Conv2d(113, 113, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=113, bias=False)\n",
       "        (conv1-2): Conv2d(113, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Sequential(\n",
       "        (conv2-0): Conv2d(256, 113, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2-1): Conv2d(113, 113, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=113, bias=False)\n",
       "        (conv2-2): Conv2d(113, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (conv1-0): Conv2d(256, 113, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv1-1): Conv2d(113, 113, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=113, bias=False)\n",
       "        (conv1-2): Conv2d(113, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Sequential(\n",
       "        (conv2-0): Conv2d(256, 113, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2-1): Conv2d(113, 113, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=113, bias=False)\n",
       "        (conv2-2): Conv2d(113, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (conv1-0): Conv2d(256, 151, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv1-1): Conv2d(151, 151, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=151, bias=False)\n",
       "        (conv1-2): Conv2d(151, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Sequential(\n",
       "        (conv2-0): Conv2d(512, 228, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2-1): Conv2d(228, 228, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=228, bias=False)\n",
       "        (conv2-2): Conv2d(228, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (conv1-0): Conv2d(512, 228, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv1-1): Conv2d(228, 228, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=228, bias=False)\n",
       "        (conv1-2): Conv2d(228, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Sequential(\n",
       "        (conv2-0): Conv2d(512, 228, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2-1): Conv2d(228, 228, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=228, bias=False)\n",
       "        (conv2-2): Conv2d(228, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (conv1-0): Conv2d(512, 228, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv1-1): Conv2d(228, 228, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=228, bias=False)\n",
       "        (conv1-2): Conv2d(228, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Sequential(\n",
       "        (conv2-0): Conv2d(512, 228, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2-1): Conv2d(228, 228, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=228, bias=False)\n",
       "        (conv2-2): Conv2d(228, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cpu')\n",
    "compressed_model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "flopco_m = FlopCo(model)\n",
    "flopco_cm = FlopCo(compressed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2223035384295993"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flopco_m.total_flops / flopco_cm.total_flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'conv1': [236027904],\n",
       "             'bn1': [3211264],\n",
       "             'relu': [802816],\n",
       "             'maxpool': [1806336],\n",
       "             'layer1.0.conv1': [231211008],\n",
       "             'layer1.0.bn1': [802816],\n",
       "             'layer1.0.relu': [200704, 200704],\n",
       "             'layer1.0.conv2': [231211008],\n",
       "             'layer1.0.bn2': [802816],\n",
       "             'layer1.1.conv1': [231211008],\n",
       "             'layer1.1.bn1': [802816],\n",
       "             'layer1.1.relu': [200704, 200704],\n",
       "             'layer1.1.conv2': [231211008],\n",
       "             'layer1.1.bn2': [802816],\n",
       "             'layer1.2.conv1': [231211008],\n",
       "             'layer1.2.bn1': [802816],\n",
       "             'layer1.2.relu': [200704, 200704],\n",
       "             'layer1.2.conv2': [231211008],\n",
       "             'layer1.2.bn2': [802816],\n",
       "             'layer2.0.conv1': [115605504],\n",
       "             'layer2.0.bn1': [401408],\n",
       "             'layer2.0.relu': [100352, 100352],\n",
       "             'layer2.0.conv2': [231211008],\n",
       "             'layer2.0.bn2': [401408],\n",
       "             'layer2.0.downsample.0': [12845056],\n",
       "             'layer2.0.downsample.1': [401408],\n",
       "             'layer2.1.conv1': [231211008],\n",
       "             'layer2.1.bn1': [401408],\n",
       "             'layer2.1.relu': [100352, 100352],\n",
       "             'layer2.1.conv2': [231211008],\n",
       "             'layer2.1.bn2': [401408],\n",
       "             'layer2.2.conv1': [231211008],\n",
       "             'layer2.2.bn1': [401408],\n",
       "             'layer2.2.relu': [100352, 100352],\n",
       "             'layer2.2.conv2': [231211008],\n",
       "             'layer2.2.bn2': [401408],\n",
       "             'layer2.3.conv1': [231211008],\n",
       "             'layer2.3.bn1': [401408],\n",
       "             'layer2.3.relu': [100352, 100352],\n",
       "             'layer2.3.conv2': [231211008],\n",
       "             'layer2.3.bn2': [401408],\n",
       "             'layer3.0.conv1': [115605504],\n",
       "             'layer3.0.bn1': [200704],\n",
       "             'layer3.0.relu': [50176, 50176],\n",
       "             'layer3.0.conv2': [231211008],\n",
       "             'layer3.0.bn2': [200704],\n",
       "             'layer3.0.downsample.0': [12845056],\n",
       "             'layer3.0.downsample.1': [200704],\n",
       "             'layer3.1.conv1': [231211008],\n",
       "             'layer3.1.bn1': [200704],\n",
       "             'layer3.1.relu': [50176, 50176],\n",
       "             'layer3.1.conv2': [231211008],\n",
       "             'layer3.1.bn2': [200704],\n",
       "             'layer3.2.conv1': [231211008],\n",
       "             'layer3.2.bn1': [200704],\n",
       "             'layer3.2.relu': [50176, 50176],\n",
       "             'layer3.2.conv2': [231211008],\n",
       "             'layer3.2.bn2': [200704],\n",
       "             'layer3.3.conv1': [231211008],\n",
       "             'layer3.3.bn1': [200704],\n",
       "             'layer3.3.relu': [50176, 50176],\n",
       "             'layer3.3.conv2': [231211008],\n",
       "             'layer3.3.bn2': [200704],\n",
       "             'layer3.4.conv1': [231211008],\n",
       "             'layer3.4.bn1': [200704],\n",
       "             'layer3.4.relu': [50176, 50176],\n",
       "             'layer3.4.conv2': [231211008],\n",
       "             'layer3.4.bn2': [200704],\n",
       "             'layer3.5.conv1': [231211008],\n",
       "             'layer3.5.bn1': [200704],\n",
       "             'layer3.5.relu': [50176, 50176],\n",
       "             'layer3.5.conv2': [231211008],\n",
       "             'layer3.5.bn2': [200704],\n",
       "             'layer4.0.conv1': [115605504],\n",
       "             'layer4.0.bn1': [100352],\n",
       "             'layer4.0.relu': [25088, 25088],\n",
       "             'layer4.0.conv2': [231211008],\n",
       "             'layer4.0.bn2': [100352],\n",
       "             'layer4.0.downsample.0': [12845056],\n",
       "             'layer4.0.downsample.1': [100352],\n",
       "             'layer4.1.conv1': [231211008],\n",
       "             'layer4.1.bn1': [100352],\n",
       "             'layer4.1.relu': [25088, 25088],\n",
       "             'layer4.1.conv2': [231211008],\n",
       "             'layer4.1.bn2': [100352],\n",
       "             'layer4.2.conv1': [231211008],\n",
       "             'layer4.2.bn1': [100352],\n",
       "             'layer4.2.relu': [25088, 25088],\n",
       "             'layer4.2.conv2': [231211008],\n",
       "             'layer4.2.bn2': [100352],\n",
       "             'fc': [1024512]})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flopco_m.flops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3x3xcxc\n",
    "\n",
    "params: 9cc\n",
    "flops: 9cchw\n",
    "\n",
    "1x1xcxr, 3x3x1xr, 1x1xrxc\n",
    "\n",
    "params: cr + 9r + cr= r(2c + 9)\n",
    "flops: crhw + 9rhw + crhw = r(2c + 9)hw\n",
    "\n",
    "paramx_nx = 9cc / r(2c + 9)\n",
    "flops_nx = 9cchw / r(2c + 9)hw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\" \n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to('cuda')\n",
    "compressed_model.to('cuda')\n",
    "\n",
    "x = torch.randn(32, 3, 224, 224).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.7 ms ± 7.41 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit y = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.4 ms ± 284 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit y = compressed_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to('cpu')\n",
    "compressed_model.to('cpu')\n",
    "\n",
    "x = torch.randn(1, 3, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.47 s ± 113 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit y = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.2 s ± 1.94 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit y = compressed_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
