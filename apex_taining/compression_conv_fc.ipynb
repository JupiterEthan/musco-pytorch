{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catalyst.dl.runner import SupervisedRunner\n",
    "from catalyst.dl.callbacks import EarlyStoppingCallback, AccuracyCallback\n",
    "from catalyst.dl.core import Callback\n",
    "\n",
    "from collections import OrderedDict, defaultdict\n",
    "\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = OrderedDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building imagenet data loader with 16 workers\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import dataloaders\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "# DATA_ROOT = \"/workspace/raid/data/datasets\"\n",
    "DATA_ROOT = \"/gpfs/gpfs0/e.ponomarev/\"\n",
    "dataset_name = 'imagenet'\n",
    "\n",
    "bs = 128\n",
    "num_workers = 16\n",
    "\n",
    "if dataset_name == 'cifar10':\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    DATA_PATH = \"{}/cifar10\".format(DATA_ROOT)\n",
    "\n",
    "    loaders[\"valid\"] = torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR10(root=DATA_PATH, train=False, transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]),  download = True),\n",
    "        batch_size=bs, shuffle=False,\n",
    "        num_workers=num_workers, pin_memory=True)\n",
    "elif dataset_name == 'imagenet':\n",
    "    loaders[\"valid\"] = dataloaders.get_loader(batch_size=bs,\n",
    "                                        data_name = 'imagenet',\n",
    "                                        data_root = DATA_ROOT,\n",
    "                                        num_workers = num_workers, \n",
    "                                        pin_memory = True)['val']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class MyInferCallback(Callback):\n",
    "    \n",
    "    \n",
    "    def __init__(self, out_dir=None, out_prefix=None):\n",
    "        self.out_dir = out_dir\n",
    "        self.out_prefix = out_prefix\n",
    "        self.predictions = defaultdict(lambda: [])\n",
    "        self._keys_from_state = [\"out_dir\", \"out_prefix\"]\n",
    "\n",
    "    def on_stage_start(self, state):\n",
    "        for key in self._keys_from_state:\n",
    "            value = getattr(state, key, None)\n",
    "            if value is not None:\n",
    "                setattr(self, key, value)\n",
    "        # assert self.out_prefix is not None\n",
    "        if self.out_dir is not None:\n",
    "            self.out_prefix = str(self.out_dir) + \"/\" + str(self.out_prefix)\n",
    "        if self.out_prefix is not None:\n",
    "            os.makedirs(os.path.dirname(self.out_prefix), exist_ok=True)\n",
    "\n",
    "    def on_loader_start(self, state):\n",
    "        self.predictions = defaultdict(lambda: [])\n",
    "        self.inputs = defaultdict(lambda: [])\n",
    "\n",
    "    def on_batch_end(self, state):\n",
    "        dct = state.output\n",
    "        dct = {key: value.detach().cpu().numpy() for key, value in dct.items()}\n",
    "        for key, value in dct.items():\n",
    "            self.predictions[key].append(value)\n",
    "            \n",
    "        dct = state.input\n",
    "        dct = {key: value.detach().cpu().numpy() for key, value in dct.items()}\n",
    "        for key, value in dct.items():\n",
    "            self.inputs[key].append(value)\n",
    "\n",
    "    def on_loader_end(self, state):\n",
    "        from catalyst.dl.metrics import accuracy\n",
    "        self.predictions = {\n",
    "            key: np.concatenate(value, axis=0)\n",
    "            for key, value in self.predictions.items()\n",
    "        }\n",
    "        self.inputs = {\n",
    "            key: np.concatenate(value, axis=0)\n",
    "            for key, value in self.inputs.items()\n",
    "        }\n",
    "        y_true = torch.tensor(self.inputs['targets'])\n",
    "        y_pred = torch.tensor(self.predictions['logits'])\n",
    "        self.accuracy_score = torch.stack(accuracy(y_pred,y_true,topk=(1, 3, 5))).numpy().astype('float32')\n",
    "        self.accuracy_score = np.squeeze(self.accuracy_score)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def run(model, device = 'cuda'):\n",
    "\n",
    "    runner = SupervisedRunner()\n",
    "    runner.infer(\n",
    "        model=model.to(device),\n",
    "        verbose = True,\n",
    "        loaders=OrderedDict([(\"infer\", loaders[\"valid\"])]),\n",
    "        callbacks=[\n",
    "            MyInferCallback(),\n",
    "            AccuracyCallback(accuracy_args=[1, 3, 5])\n",
    "        ],\n",
    "    )\n",
    "    score = runner.callbacks[0].accuracy_score\n",
    "    del model\n",
    "    del runner\n",
    "    torch.cuda.empty_cache()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "scores0 = run(model)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "scores0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from model_utils import load_model\n",
    "from torchvision.models import resnet34, resnet18\n",
    "\n",
    "# MODEL_NAME = 'vgg16_imagenet'\n",
    "# MODEL_NAME = 'resnet50_imagenet'\n",
    "MODEL_NAME = 'resnet18_imagenet'\n",
    "# MODEL_NAME = 'resnet34_imagenet'\n",
    "\n",
    "# MODEL_NAME = 'faster_rcnn_vgg16\n",
    "# MODEL_NAME = 'faster_rcnn_resnet50'\n",
    "\n",
    "\n",
    "# # Uncomment if MODEL_NAME = 'faster_rcnn_resnet50'\n",
    "# sys.path.append('/workspace/home/jgusak/maxvol_objects/facebook_frcnn/')\n",
    "# import maskrcnn_benchmark\n",
    "\n",
    "# model = load_model(MODEL_NAME)\n",
    "\n",
    "model = resnet18(pretrained = True)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in model.parameters():\n",
    "#     print(p.requires_grad)\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/1 * Epoch (infer): 100% 391/391 [11:11<00:00,  3.10it/s, _timers/_fps=461.658, accuracy01=42.500, accuracy03=73.750, accuracy05=77.500] \n"
     ]
    }
   ],
   "source": [
    "from catalyst.dl.callbacks import InferCallback\n",
    "from collections import OrderedDict\n",
    "\n",
    "runner = SupervisedRunner()\n",
    "\n",
    "model = model.to('cuda')\n",
    "runner.infer(\n",
    "    model=model,\n",
    "    loaders = OrderedDict([(\"infer\", loaders[\"valid\"])]),\n",
    "    callbacks=[InferCallback(),\n",
    "               AccuracyCallback(accuracy_args=[1, 3, 5])],\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "del runner\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get  all  layers\n",
    "\n",
    "Function  **get_layer_names()** returns names of model layers (convolutional and fully connected) and boolean mask for convolutional layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['conv1' 'layer1.0.conv1' 'layer1.0.conv2' 'layer1.1.conv1'\n",
      " 'layer1.1.conv2' 'layer2.0.conv1' 'layer2.0.conv2'\n",
      " 'layer2.0.downsample.0' 'layer2.1.conv1' 'layer2.1.conv2'\n",
      " 'layer3.0.conv1' 'layer3.0.conv2' 'layer3.0.downsample.0'\n",
      " 'layer3.1.conv1' 'layer3.1.conv2' 'layer4.0.conv1' 'layer4.0.conv2'\n",
      " 'layer4.0.downsample.0' 'layer4.1.conv1' 'layer4.1.conv2']\n",
      "['fc']\n"
     ]
    }
   ],
   "source": [
    "from model_utils import get_layer_names\n",
    "\n",
    "layer_names, conv_layer_mask = get_layer_names(model)\n",
    "\n",
    "\n",
    "fc_layer_mask = (1 - conv_layer_mask).astype(bool)\n",
    "\n",
    "print(layer_names[conv_layer_mask])\n",
    "print(layer_names[fc_layer_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auxiliary function\n",
    "import numpy as np\n",
    "def split_resnet_layers_by_blocks(lnames):\n",
    "#     starts = ['body.stem.conv1'] + ['body.layer{}'.format(i) for i in range(1,5)]\n",
    "    starts = ['conv1'] + ['layer{}'.format(i) for i in range(1,5)]\n",
    "\n",
    "\n",
    "    start_idx = 0\n",
    "    blocks_idxs = []\n",
    "    layer_names_by_blocks = []\n",
    "\n",
    "    for s in starts:\n",
    "        curr_block =  [l for l in lnames if l.startswith(s)]\n",
    "        layer_names_by_blocks.append(curr_block)\n",
    "\n",
    "        blocks_idxs.append(np.arange(start_idx, start_idx+len(curr_block)))\n",
    "        start_idx += len(curr_block)\n",
    "\n",
    "    return blocks_idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compress selected layers\n",
    "\n",
    "For **convolutional** layers\n",
    "- Set **decomposition**: 'tucker2', 'cp3' or 'cp4'\n",
    "- Set  decomposition **ranks** for convolutional layers (namely, ranks we use to decompose convolutional weight tensors). \n",
    "  - In Tucker2 case, for one layer \n",
    "      - If **rank = None**, the layer won't be decomposed.\n",
    "      - Elif **rank = 0**, then  VBMF method with **vbmf_weaken_factor**  will be used to select (rank_cout, rank_cin).\n",
    "      - Elif **rank = (-scalar) < 0**, then values (rank_cout, rank_cin) will be choosen as maximal values which allow **(sacalar x) layer parameter reduction**.\n",
    "      - Else **rank = tuple** and determines absolute ranks values (rank_cout, rank_cin)\n",
    "  - In CP case, rank for one layer is a scalar\n",
    "      - If **rank = None**, the layer won't be decomposed.\n",
    "      - Elif **rank = (-scalar) < 0** then value for rank will be choosen as maximal rank which allows **(sacalar x) layer parameter reduction**.\n",
    "      - Else **rank = scalar > 0** and determines absolute rank value.\n",
    "      \n",
    "For **fully connected** layers\n",
    "- Set **decomposition** = 'svd'\n",
    "- Set decomposition for linear layers (namely, ranks we use to factorize weight matrices)\n",
    "    - In SVD case, rank for one layer is a scalar\n",
    "      - If **rank = None**, the layer won't be decomposed.\n",
    "      - Elif **rank = 0**, then  VBMF method with **vbmf_weaken_factor**  will be used to select rank.\n",
    "      - Elif **rank = (-scalar) < 0** then value for rank will be choosen as maximal rank which allows **(sacalar x) layer parameter reduction**.\n",
    "      - Else **rank = scalar > 0** and determines absolute rank value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorly in /trinity/home/y.gusak/.local/lib/python3.6/site-packages (0.4.3)\r\n",
      "Requirement already satisfied: scipy in /trinity/shared/opt/python-3.6.8/lib/python3.6/site-packages (from tensorly) (1.2.0)\r\n",
      "Requirement already satisfied: numpy in /trinity/shared/opt/python-3.6.8/lib/python3.6/site-packages (from tensorly) (1.16.0)\r\n",
      "Requirement already satisfied: nose in /trinity/home/y.gusak/.local/lib/python3.6/site-packages (from tensorly) (1.3.7)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install  tensorly --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensor_compression import get_compressed_model\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "# decomposition_conv = 'cp4'\n",
    "# decomposition_conv = 'cp3'\n",
    "decomposition_conv = 'tucker2'\n",
    "\n",
    "decomposition_fc = 'svd'\n",
    "\n",
    "RANK_SELECTION = 'vbmf'\n",
    "# RANK_SELECTION = 'nx'\n",
    "# RANK_SELECTION = 'custom'\n",
    "\n",
    "if RANK_SELECTION == 'vbmf':\n",
    "    WEAKEN_FACTOR = 0.1\n",
    "    X_FACTOR = 0\n",
    "    rank_selection_suffix = \"/wf:{}\".format(WEAKEN_FACTOR)\n",
    "elif RANK_SELECTION == 'nx':\n",
    "    WEAKEN_FACTOR = None  \n",
    "    X_FACTOR = 10\n",
    "    rank_selection_suffix = \"/{}x\".format(X_FACTOR)\n",
    "    \n",
    "    \n",
    "if MODEL_NAME == 'vgg16_imagenet':\n",
    "    ranks_conv = [None] + [-X_FACTOR]*(len(layer_names[conv_layer_mask])-1)\n",
    "\n",
    "elif MODEL_NAME == 'resnet50_imagenet':\n",
    "    ranks_conv = [None if not name.endswith('conv2') else -X_FACTOR\n",
    "                  for name in layer_names[conv_layer_mask]]\n",
    "\n",
    "elif MODEL_NAME in ['resnet18_imagenet', 'resnet34_imagenet']:\n",
    "    ranks_conv = [None if name == 'conv1' or not (name.endswith('conv2') or\n",
    "                                                  name.endswith('conv1')) else -X_FACTOR\n",
    "              for name in layer_names[conv_layer_mask]]\n",
    "\n",
    "elif MODEL_NAME ==  'faster_rcnn_resnet50':\n",
    "    ranks_conv = [None if not name.endswith('body.conv2') else -X_FACTOR\n",
    "                  for name in layer_names[conv_layer_mask]]\n",
    "\n",
    "# ranks_fc = [-X_FACTOR]*(len(layer_names[fc_layer_mask]))\n",
    "ranks_fc = [None]*(len(layer_names[fc_layer_mask]))\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "ranks = np.array([None]*len(layer_names))\n",
    "ranks[conv_layer_mask] = ranks_conv\n",
    "ranks[fc_layer_mask] = ranks_fc\n",
    "\n",
    "decompositions = np.array([None]*len(layer_names))\n",
    "decompositions[conv_layer_mask] = decomposition_conv\n",
    "decompositions[fc_layer_mask] = decomposition_fc\n",
    "\n",
    "CONV_SPLIT = 1\n",
    "FC_SPLIT = 1\n",
    "n_layers = len(layer_names)\n",
    "\n",
    "RESNET_SPLIT = False\n",
    "if MODEL_NAME in ['resnet50_imagenet', 'resnet34_imagenet', 'resnet18_imagenet',  'faster_rcnn_resnet50'] and RESNET_SPLIT:\n",
    "    split_tuples = split_resnet_layers_by_blocks(layer_names[conv_layer_mask])[::-1]\n",
    "else:\n",
    "    split_tuples = np.array_split(np.arange(n_layers)[conv_layer_mask], CONV_SPLIT)[::-1]\n",
    "split_tuples.append(np.array_split(np.arange(n_layers)[fc_layer_mask], FC_SPLIT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['conv1' 'layer1.0.conv1' 'layer1.0.conv2' 'layer1.1.conv1'\n",
      " 'layer1.1.conv2' 'layer2.0.conv1' 'layer2.0.conv2'\n",
      " 'layer2.0.downsample.0' 'layer2.1.conv1' 'layer2.1.conv2'\n",
      " 'layer3.0.conv1' 'layer3.0.conv2' 'layer3.0.downsample.0'\n",
      " 'layer3.1.conv1' 'layer3.1.conv2' 'layer4.0.conv1' 'layer4.0.conv2'\n",
      " 'layer4.0.downsample.0' 'layer4.1.conv1' 'layer4.1.conv2']\n",
      "['fc']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/trinity/shared/opt/python-3.6.8/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning:\n",
      "\n",
      "Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tupl in split_tuples:\n",
    "    print(layer_names[tupl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['conv1' 'layer1.0.conv1' 'layer1.0.conv2' 'layer1.1.conv1'\n",
      " 'layer1.1.conv2' 'layer2.0.conv1' 'layer2.0.conv2'\n",
      " 'layer2.0.downsample.0' 'layer2.1.conv1' 'layer2.1.conv2'\n",
      " 'layer3.0.conv1' 'layer3.0.conv2' 'layer3.0.downsample.0'\n",
      " 'layer3.1.conv1' 'layer3.1.conv2' 'layer4.0.conv1' 'layer4.0.conv2'\n",
      " 'layer4.0.downsample.0' 'layer4.1.conv1' 'layer4.1.conv2'] [None 0 0 0 0 0 0 None 0 0 0 0 None 0 0 0 0 None 0 0]\n",
      "-------------------- SVD time:  0.019542694091796875\n",
      "------------------- VBMF time :  0.02077317237854004\n",
      "-------------------- SVD time:  0.01649022102355957\n",
      "------------------- VBMF time :  0.01769709587097168\n",
      "-------------------- SVD time:  0.016348838806152344\n",
      "------------------- VBMF time :  0.01729607582092285\n",
      "-------------------- SVD time:  0.016177892684936523\n",
      "------------------- VBMF time :  0.01706409454345703\n",
      "-------------------- SVD time:  0.0170290470123291\n",
      "------------------- VBMF time :  0.017976045608520508\n",
      "-------------------- SVD time:  0.018669843673706055\n",
      "------------------- VBMF time :  0.019582271575927734\n",
      "-------------------- SVD time:  0.017344951629638672\n",
      "------------------- VBMF time :  0.018139362335205078\n",
      "-------------------- SVD time:  0.016561269760131836\n",
      "------------------- VBMF time :  0.017540693283081055\n",
      "-------------------- SVD time:  0.0315709114074707\n",
      "------------------- VBMF time :  0.03251194953918457\n",
      "-------------------- SVD time:  0.07103109359741211\n",
      "------------------- VBMF time :  0.07203006744384766\n",
      "-------------------- SVD time:  0.12536931037902832\n",
      "------------------- VBMF time :  0.12648606300354004\n",
      "-------------------- SVD time:  0.1220390796661377\n",
      "------------------- VBMF time :  0.12303709983825684\n",
      "-------------------- SVD time:  0.12233304977416992\n",
      "------------------- VBMF time :  0.12333035469055176\n",
      "-------------------- SVD time:  0.11910820007324219\n",
      "------------------- VBMF time :  0.11992716789245605\n",
      "-------------------- SVD time:  0.12065768241882324\n",
      "------------------- VBMF time :  0.12146997451782227\n",
      "-------------------- SVD time:  0.1183629035949707\n",
      "------------------- VBMF time :  0.11944866180419922\n",
      "-------------------- SVD time:  0.2551407814025879\n",
      "------------------- VBMF time :  0.2563633918762207\n",
      "-------------------- SVD time:  0.8480377197265625\n",
      "------------------- VBMF time :  0.8489968776702881\n",
      "-------------------- SVD time:  1.0011601448059082\n",
      "------------------- VBMF time :  1.0023937225341797\n",
      "-------------------- SVD time:  0.8967018127441406\n",
      "------------------- VBMF time :  0.8977756500244141\n",
      "-------------------- SVD time:  1.0000205039978027\n",
      "------------------- VBMF time :  1.0010685920715332\n",
      "-------------------- SVD time:  0.9128026962280273\n",
      "------------------- VBMF time :  0.9139571189880371\n",
      "-------------------- SVD time:  1.1915335655212402\n",
      "------------------- VBMF time :  1.1924026012420654\n",
      "-------------------- SVD time:  1.0383880138397217\n",
      "------------------- VBMF time :  1.0394411087036133\n",
      "-------------------- SVD time:  1.1029891967773438\n",
      "------------------- VBMF time :  1.104247808456421\n",
      "-------------------- SVD time:  6.0607078075408936\n",
      "------------------- VBMF time :  6.061912775039673\n",
      "-------------------- SVD time:  6.806468963623047\n",
      "------------------- VBMF time :  6.807718992233276\n",
      "-------------------- SVD time:  6.628890752792358\n",
      "------------------- VBMF time :  6.6307899951934814\n",
      "-------------------- SVD time:  6.545221567153931\n",
      "------------------- VBMF time :  6.546994209289551\n",
      "-------------------- SVD time:  6.529294490814209\n",
      "------------------- VBMF time :  6.530341386795044\n",
      "-------------------- SVD time:  6.901761293411255\n",
      "------------------- VBMF time :  6.902815580368042\n",
      "-------------------- SVD time:  6.524949312210083\n",
      "------------------- VBMF time :  6.52612829208374\n",
      "================ time : 83.22170877456665\n",
      "0/1 * Epoch (infer): 100% 391/391 [10:43<00:00,  7.01it/s, _timers/_fps=312.587, accuracy01=36.250, accuracy03=67.500, accuracy05=71.250]   "
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'catalyst.dl.metrics'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-48f1ec8421d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'================ time : {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompressed_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#     scores[layer_names[tupl[0]][0]] = score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-13131eb441f2>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(model, device)\u001b[0m\n\u001b[1;32m      8\u001b[0m         callbacks=[\n\u001b[1;32m      9\u001b[0m             \u001b[0mMyInferCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mAccuracyCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         ],\n\u001b[1;32m     12\u001b[0m     )\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/catalyst/dl/runner/supervised.py\u001b[0m in \u001b[0;36minfer\u001b[0;34m(self, model, loaders, callbacks, verbose, state_kwargs, fp16, check)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mdistributed_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         )\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/catalyst/dl/core/runner.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(self, experiment, check)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/catalyst/dl/core/runner.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self, stage)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch_start\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/catalyst/dl/core/runner.py\u001b[0m in \u001b[0;36m_run_epoch\u001b[0;34m(self, loaders)\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneed_backward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loader_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/catalyst/dl/core/runner.py\u001b[0m in \u001b[0;36m_run_event\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m                 \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"on_{event}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"on_{event}_post\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-f4f5eb111671>\u001b[0m in \u001b[0;36mon_loader_end\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_loader_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mcatalyst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         self.predictions = {\n\u001b[1;32m     39\u001b[0m             \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'catalyst.dl.metrics'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "scores = defaultdict(list)\n",
    "\n",
    "compressed_model = copy.deepcopy(model.cpu())\n",
    "for tupl in split_tuples:\n",
    "    lname, rank, decomposition = layer_names[tupl], ranks[tupl], decompositions[tupl]\n",
    "    print(lname, rank)\n",
    "    start = time.time()\n",
    "    compressed_model = get_compressed_model(compressed_model,\n",
    "                                            ranks=rank,\n",
    "                                            layer_names=lname,\n",
    "                                            decompositions = decomposition,\n",
    "                                            vbmf_weaken_factor=WEAKEN_FACTOR)\n",
    "    end = time.time()\n",
    "    print('================ time : {}'.format(end - start))\n",
    "    score = run(copy.deepcopy(compressed_model))\n",
    "    print(score)\n",
    "#     scores[layer_names[tupl[0]][0]] = score\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def count_params(model):\n",
    "    n_params = 0\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        n_params += param.numel()\n",
    "    return n_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.232299048353415"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_count_dict_m = count_params(model)\n",
    "params_count_dict_cm = count_params(compressed_model)\n",
    "\n",
    "params_count_dict_m / params_count_dict_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_tuples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute FLOPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compressed_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from flopco import FlopCo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (conv1-0): Conv2d(64, 36, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv1-1): Conv2d(36, 36, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=36, bias=False)\n",
       "        (conv1-2): Conv2d(36, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Sequential(\n",
       "        (conv2-0): Conv2d(128, 55, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2-1): Conv2d(55, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=55, bias=False)\n",
       "        (conv2-2): Conv2d(55, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (conv1-0): Conv2d(128, 55, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv1-1): Conv2d(55, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=55, bias=False)\n",
       "        (conv1-2): Conv2d(55, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Sequential(\n",
       "        (conv2-0): Conv2d(128, 55, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2-1): Conv2d(55, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=55, bias=False)\n",
       "        (conv2-2): Conv2d(55, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (conv1-0): Conv2d(128, 55, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv1-1): Conv2d(55, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=55, bias=False)\n",
       "        (conv1-2): Conv2d(55, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Sequential(\n",
       "        (conv2-0): Conv2d(128, 55, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2-1): Conv2d(55, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=55, bias=False)\n",
       "        (conv2-2): Conv2d(55, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (conv1-0): Conv2d(128, 55, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv1-1): Conv2d(55, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=55, bias=False)\n",
       "        (conv1-2): Conv2d(55, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Sequential(\n",
       "        (conv2-0): Conv2d(128, 55, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2-1): Conv2d(55, 55, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=55, bias=False)\n",
       "        (conv2-2): Conv2d(55, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (conv1-0): Conv2d(128, 75, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv1-1): Conv2d(75, 75, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=75, bias=False)\n",
       "        (conv1-2): Conv2d(75, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Sequential(\n",
       "        (conv2-0): Conv2d(256, 113, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2-1): Conv2d(113, 113, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=113, bias=False)\n",
       "        (conv2-2): Conv2d(113, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (conv1-0): Conv2d(256, 113, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv1-1): Conv2d(113, 113, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=113, bias=False)\n",
       "        (conv1-2): Conv2d(113, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Sequential(\n",
       "        (conv2-0): Conv2d(256, 113, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2-1): Conv2d(113, 113, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=113, bias=False)\n",
       "        (conv2-2): Conv2d(113, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (conv1-0): Conv2d(256, 113, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv1-1): Conv2d(113, 113, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=113, bias=False)\n",
       "        (conv1-2): Conv2d(113, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Sequential(\n",
       "        (conv2-0): Conv2d(256, 113, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2-1): Conv2d(113, 113, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=113, bias=False)\n",
       "        (conv2-2): Conv2d(113, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (3): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (conv1-0): Conv2d(256, 113, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv1-1): Conv2d(113, 113, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=113, bias=False)\n",
       "        (conv1-2): Conv2d(113, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Sequential(\n",
       "        (conv2-0): Conv2d(256, 113, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2-1): Conv2d(113, 113, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=113, bias=False)\n",
       "        (conv2-2): Conv2d(113, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (4): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (conv1-0): Conv2d(256, 113, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv1-1): Conv2d(113, 113, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=113, bias=False)\n",
       "        (conv1-2): Conv2d(113, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Sequential(\n",
       "        (conv2-0): Conv2d(256, 113, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2-1): Conv2d(113, 113, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=113, bias=False)\n",
       "        (conv2-2): Conv2d(113, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (5): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (conv1-0): Conv2d(256, 113, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv1-1): Conv2d(113, 113, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=113, bias=False)\n",
       "        (conv1-2): Conv2d(113, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Sequential(\n",
       "        (conv2-0): Conv2d(256, 113, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2-1): Conv2d(113, 113, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=113, bias=False)\n",
       "        (conv2-2): Conv2d(113, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (conv1-0): Conv2d(256, 151, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv1-1): Conv2d(151, 151, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=151, bias=False)\n",
       "        (conv1-2): Conv2d(151, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Sequential(\n",
       "        (conv2-0): Conv2d(512, 228, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2-1): Conv2d(228, 228, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=228, bias=False)\n",
       "        (conv2-2): Conv2d(228, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (conv1-0): Conv2d(512, 228, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv1-1): Conv2d(228, 228, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=228, bias=False)\n",
       "        (conv1-2): Conv2d(228, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Sequential(\n",
       "        (conv2-0): Conv2d(512, 228, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2-1): Conv2d(228, 228, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=228, bias=False)\n",
       "        (conv2-2): Conv2d(228, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (2): BasicBlock(\n",
       "      (conv1): Sequential(\n",
       "        (conv1-0): Conv2d(512, 228, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv1-1): Conv2d(228, 228, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=228, bias=False)\n",
       "        (conv1-2): Conv2d(228, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Sequential(\n",
       "        (conv2-0): Conv2d(512, 228, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (conv2-1): Conv2d(228, 228, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=228, bias=False)\n",
       "        (conv2-2): Conv2d(228, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cpu')\n",
    "compressed_model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "flopco_m = FlopCo(model)\n",
    "flopco_cm = FlopCo(compressed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2223035384295993"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flopco_m.total_flops / flopco_cm.total_flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'conv1': [236027904],\n",
       "             'bn1': [3211264],\n",
       "             'relu': [802816],\n",
       "             'maxpool': [1806336],\n",
       "             'layer1.0.conv1': [231211008],\n",
       "             'layer1.0.bn1': [802816],\n",
       "             'layer1.0.relu': [200704, 200704],\n",
       "             'layer1.0.conv2': [231211008],\n",
       "             'layer1.0.bn2': [802816],\n",
       "             'layer1.1.conv1': [231211008],\n",
       "             'layer1.1.bn1': [802816],\n",
       "             'layer1.1.relu': [200704, 200704],\n",
       "             'layer1.1.conv2': [231211008],\n",
       "             'layer1.1.bn2': [802816],\n",
       "             'layer1.2.conv1': [231211008],\n",
       "             'layer1.2.bn1': [802816],\n",
       "             'layer1.2.relu': [200704, 200704],\n",
       "             'layer1.2.conv2': [231211008],\n",
       "             'layer1.2.bn2': [802816],\n",
       "             'layer2.0.conv1': [115605504],\n",
       "             'layer2.0.bn1': [401408],\n",
       "             'layer2.0.relu': [100352, 100352],\n",
       "             'layer2.0.conv2': [231211008],\n",
       "             'layer2.0.bn2': [401408],\n",
       "             'layer2.0.downsample.0': [12845056],\n",
       "             'layer2.0.downsample.1': [401408],\n",
       "             'layer2.1.conv1': [231211008],\n",
       "             'layer2.1.bn1': [401408],\n",
       "             'layer2.1.relu': [100352, 100352],\n",
       "             'layer2.1.conv2': [231211008],\n",
       "             'layer2.1.bn2': [401408],\n",
       "             'layer2.2.conv1': [231211008],\n",
       "             'layer2.2.bn1': [401408],\n",
       "             'layer2.2.relu': [100352, 100352],\n",
       "             'layer2.2.conv2': [231211008],\n",
       "             'layer2.2.bn2': [401408],\n",
       "             'layer2.3.conv1': [231211008],\n",
       "             'layer2.3.bn1': [401408],\n",
       "             'layer2.3.relu': [100352, 100352],\n",
       "             'layer2.3.conv2': [231211008],\n",
       "             'layer2.3.bn2': [401408],\n",
       "             'layer3.0.conv1': [115605504],\n",
       "             'layer3.0.bn1': [200704],\n",
       "             'layer3.0.relu': [50176, 50176],\n",
       "             'layer3.0.conv2': [231211008],\n",
       "             'layer3.0.bn2': [200704],\n",
       "             'layer3.0.downsample.0': [12845056],\n",
       "             'layer3.0.downsample.1': [200704],\n",
       "             'layer3.1.conv1': [231211008],\n",
       "             'layer3.1.bn1': [200704],\n",
       "             'layer3.1.relu': [50176, 50176],\n",
       "             'layer3.1.conv2': [231211008],\n",
       "             'layer3.1.bn2': [200704],\n",
       "             'layer3.2.conv1': [231211008],\n",
       "             'layer3.2.bn1': [200704],\n",
       "             'layer3.2.relu': [50176, 50176],\n",
       "             'layer3.2.conv2': [231211008],\n",
       "             'layer3.2.bn2': [200704],\n",
       "             'layer3.3.conv1': [231211008],\n",
       "             'layer3.3.bn1': [200704],\n",
       "             'layer3.3.relu': [50176, 50176],\n",
       "             'layer3.3.conv2': [231211008],\n",
       "             'layer3.3.bn2': [200704],\n",
       "             'layer3.4.conv1': [231211008],\n",
       "             'layer3.4.bn1': [200704],\n",
       "             'layer3.4.relu': [50176, 50176],\n",
       "             'layer3.4.conv2': [231211008],\n",
       "             'layer3.4.bn2': [200704],\n",
       "             'layer3.5.conv1': [231211008],\n",
       "             'layer3.5.bn1': [200704],\n",
       "             'layer3.5.relu': [50176, 50176],\n",
       "             'layer3.5.conv2': [231211008],\n",
       "             'layer3.5.bn2': [200704],\n",
       "             'layer4.0.conv1': [115605504],\n",
       "             'layer4.0.bn1': [100352],\n",
       "             'layer4.0.relu': [25088, 25088],\n",
       "             'layer4.0.conv2': [231211008],\n",
       "             'layer4.0.bn2': [100352],\n",
       "             'layer4.0.downsample.0': [12845056],\n",
       "             'layer4.0.downsample.1': [100352],\n",
       "             'layer4.1.conv1': [231211008],\n",
       "             'layer4.1.bn1': [100352],\n",
       "             'layer4.1.relu': [25088, 25088],\n",
       "             'layer4.1.conv2': [231211008],\n",
       "             'layer4.1.bn2': [100352],\n",
       "             'layer4.2.conv1': [231211008],\n",
       "             'layer4.2.bn1': [100352],\n",
       "             'layer4.2.relu': [25088, 25088],\n",
       "             'layer4.2.conv2': [231211008],\n",
       "             'layer4.2.bn2': [100352],\n",
       "             'fc': [1024512]})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flopco_m.flops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3x3xcxc\n",
    "\n",
    "params: 9cc\n",
    "flops: 9cchw\n",
    "\n",
    "1x1xcxr, 3x3x1xr, 1x1xrxc\n",
    "\n",
    "params: cr + 9r + cr= r(2c + 9)\n",
    "flops: crhw + 9rhw + crhw = r(2c + 9)hw\n",
    "\n",
    "paramx_nx = 9cc / r(2c + 9)\n",
    "flops_nx = 9cchw / r(2c + 9)hw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\" \n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to('cuda')\n",
    "compressed_model.to('cuda')\n",
    "\n",
    "x = torch.randn(32, 3, 224, 224).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.7 ms  7.41 s per loop (mean  std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit y = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.4 ms  284 s per loop (mean  std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit y = compressed_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to('cpu')\n",
    "compressed_model.to('cpu')\n",
    "\n",
    "x = torch.randn(1, 3, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.47 s  113 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit y = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.2 s  1.94 s per loop (mean  std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit y = compressed_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
